{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotVisibleException, TimeoutException\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"E:\\Chandralekha\\Study\\Intern_FlipRobo\\Webdriver_Selenium\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay= 10 # seconds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item1(recieved_url):\n",
    "    \n",
    "    try:\n",
    "        driver.get(recieved_url)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised:', e)\n",
    "    \n",
    "    try:\n",
    "        list_link = driver.find_element_by_xpath(\"//ul/li[2]/span/a\")\n",
    "        url_first = list_link.get_attribute('href')\n",
    "    except StaleElementReferenceException as e:\n",
    "        print ('\\n Exception raised:', e)\n",
    "    \n",
    "    driver.get(url_first)\n",
    "    time.sleep(5)\n",
    "    var_soup = sp(driver.page_source, 'html.parser')    \n",
    "\n",
    "    most_viewd_url = driver.find_element_by_xpath(\"//div[@class='mw-search-result-heading']/a\")\n",
    "    most_viewd_url_href = most_viewd_url.get_attribute('href')\n",
    "\n",
    "        \n",
    "    driver.get(most_viewd_url_href)\n",
    "    time.sleep(5)\n",
    "    var_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # extract the details\n",
    "    table = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr\")\n",
    "    \n",
    "    # extract the table contents\n",
    "    ranks = []\n",
    "    names = []\n",
    "    artists = []\n",
    "    dates = []\n",
    "    views = []\n",
    "    \n",
    "    for row in table:\n",
    "        # rank scrap\n",
    "        if (row.find_elements_by_tag_name('td')[0] is None):\n",
    "            ranks.append('--')\n",
    "        else:\n",
    "            ranks.append(row.find_elements_by_tag_name('td')[0].text)          \n",
    "\n",
    "        # name scrap\n",
    "        if (row.find_elements_by_tag_name('td')[1] is None):\n",
    "            names.append('--')\n",
    "        else:\n",
    "            names.append(row.find_elements_by_tag_name('td')[1].text)\n",
    "\n",
    "        # artist scrap\n",
    "        if (row.find_elements_by_tag_name('td')[2] is None):\n",
    "            artists.append('--')\n",
    "        else:\n",
    "            artists.append(row.find_elements_by_tag_name('td')[2].text)\n",
    "\n",
    "        # view scrap\n",
    "        if (row.find_elements_by_tag_name('td')[3] is None):\n",
    "            views.append('--')\n",
    "        else:\n",
    "                views.append(row.find_elements_by_tag_name('td')[3].text)\n",
    "\n",
    "        # date scrap\n",
    "        if (row.find_elements_by_tag_name('td')[4] is None):\n",
    "            dates.append('--')\n",
    "        else:\n",
    "            dates.append(row.find_elements_by_tag_name('td')[4].text)\n",
    "            \n",
    "    df = pd.DataFrame({'Rank': ranks, 'Name': names, 'Artist': artists, 'Upload Date': dates, 'View': views})    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                           \"Baby Shark Dance\"[28]   \n",
      "1    2.                                  \"Despacito\"[30]   \n",
      "2    3.                               \"Shape of You\"[31]   \n",
      "3    4.                              \"See You Again\"[32]   \n",
      "4    5.                       \"Johny Johny Yes Papa\"[35]   \n",
      "5    6.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
      "6    7.                                \"Uptown Funk\"[37]   \n",
      "7    8.                              \"Gangnam Style\"[38]   \n",
      "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[40]   \n",
      "9   10.                                  \"Bath Song\"[41]   \n",
      "10  11.                                      \"Sorry\"[42]   \n",
      "11  12.                                      \"Sugar\"[43]   \n",
      "12  13.                \"Phonics Song with Two Words\"[44]   \n",
      "13  14.                                       \"Roar\"[45]   \n",
      "14  15.                          \"Thinking Out Loud\"[46]   \n",
      "15  16.                             \"Counting Stars\"[47]   \n",
      "16  17.                               \"Shake It Off\"[48]   \n",
      "17  18.                             \"Dame Tu Cosita\"[49]   \n",
      "18  19.                                   \"Bailando\"[50]   \n",
      "19  20.                                    \"Lean On\"[51]   \n",
      "20  21.                                      \"Faded\"[52]   \n",
      "21  22.                                 \"Dark Horse\"[53]   \n",
      "22  23.                             \"Girls Like You\"[54]   \n",
      "23  24.                                 \"Let Her Go\"[55]   \n",
      "24  25.                                   \"Mi Gente\"[56]   \n",
      "25  26.                                      \"Hello\"[57]   \n",
      "26  27.                                \"Blank Space\"[58]   \n",
      "27  28.           \"Waka Waka (This Time for Africa)\"[59]   \n",
      "28  29.                                    \"Perfect\"[60]   \n",
      "29  30.                                   \"Chantaje\"[61]   \n",
      "\n",
      "                                               Artist        Upload Date  View  \n",
      "0                      Pinkfong Kids' Songs & Stories      June 17, 2016  7.46  \n",
      "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017  7.11  \n",
      "2                                          Ed Sheeran   January 30, 2017  5.11  \n",
      "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015  4.87  \n",
      "4                                         LooLoo Kids    October 8, 2016  4.41  \n",
      "5                                          Get Movies   January 31, 2012  4.38  \n",
      "6                    Mark Ronson featuring Bruno Mars  November 19, 2014  4.04  \n",
      "7                                                 Psy      July 15, 2012  3.89  \n",
      "8                                         Miroshka TV  February 27, 2018  3.66  \n",
      "9                          Cocomelon – Nursery Rhymes        May 2, 2018  3.38  \n",
      "10                                      Justin Bieber   October 22, 2015  3.37  \n",
      "11                                           Maroon 5   January 14, 2015  3.35  \n",
      "12                                          ChuChu TV      March 6, 2014  3.33  \n",
      "13                                         Katy Perry  September 5, 2013  3.23  \n",
      "14                                         Ed Sheeran    October 7, 2014  3.14  \n",
      "15                                        OneRepublic       May 31, 2013  3.14  \n",
      "16                                       Taylor Swift    August 18, 2014  3.00  \n",
      "17                    El Chombo featuring Cutty Ranks      April 5, 2018  2.97  \n",
      "18  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014  2.94  \n",
      "19              Major Lazer and DJ Snake featuring MØ     March 22, 2015  2.94  \n",
      "20                                        Alan Walker   December 3, 2015  2.93  \n",
      "21                       Katy Perry featuring Juicy J  February 20, 2014  2.93  \n",
      "22                         Maroon 5 featuring Cardi B       May 31, 2018  2.91  \n",
      "23                                          Passenger      July 25, 2012  2.86  \n",
      "24                         J Balvin and Willy William      June 29, 2017  2.83  \n",
      "25                                              Adele   October 22, 2015  2.76  \n",
      "26                                       Taylor Swift  November 10, 2014  2.69  \n",
      "27                    Shakira featuring Freshlyground       June 4, 2010  2.67  \n",
      "28                                         Ed Sheeran   November 9, 2017  2.66  \n",
      "29                           Shakira featuring Maluma  November 18, 2016  2.61  \n"
     ]
    }
   ],
   "source": [
    "item1('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item2(recieved_url):\n",
    "    \n",
    "    try:\n",
    "        driver.get(recieved_url)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised: ', e)\n",
    "    \n",
    "    try:\n",
    "        fixture = driver.find_element_by_xpath(\"//ul[@class='navigation__list showMoreEnabled']/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "        fixture_url = fixture.get_attribute('href')\n",
    "    except NoSuchElementException as e:\n",
    "        print ('\\n Exception raised', e)\n",
    "        \n",
    "    # Fixture page\n",
    "    driver.get(fixture_url)\n",
    "    time.sleep(5)\n",
    "    var_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # data array\n",
    "    matches = []\n",
    "    series = []\n",
    "    places = []\n",
    "    dates = []\n",
    "    times = []\n",
    "    \n",
    "    # Match scrap\n",
    "    try:\n",
    "        match_type = driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__format']\")\n",
    "        match_team = driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "    except NoSuchElementException as e:\n",
    "        print ('\\n Exception raised:', e)\n",
    "        \n",
    "    for (a,b) in zip (match_type, match_team):\n",
    "        match = a.text+' '+b.text\n",
    "        if (match is not None):\n",
    "            matches.append(match)\n",
    "        else:\n",
    "            matches.append('--')\n",
    "    \n",
    "    # Series scrap\n",
    "    try:\n",
    "        series_text = driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "    except NoSuchElementException as e:\n",
    "        print ('\\nException raised: ', e)\n",
    "    for i in series_text:\n",
    "        if (i.text is not None):\n",
    "            series.append(i.text)\n",
    "        else:\n",
    "            series.append('--')            \n",
    "            \n",
    "    # Place scrap\n",
    "    place = driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "    for i in place:\n",
    "        if (i.text is not None):\n",
    "            places.append(i.text)\n",
    "        else:\n",
    "            places.append('--')            \n",
    "    \n",
    "    # Date scrap\n",
    "    date_day = driver.find_elements_by_xpath(\"//span[@class='fixture__day']\")\n",
    "    date_dd = driver.find_elements_by_xpath(\"//span[@class='fixture__date']\")\n",
    "    date_month = driver.find_elements_by_xpath(\"//span[@class='fixture__month']\")\n",
    "    for (a,b,c) in zip(date_day, date_dd, date_month):\n",
    "        date_data = a.text+' '+b.text+' '+c.text\n",
    "        \n",
    "        if (date_data is not None):\n",
    "            dates.append(date_data)\n",
    "        else:\n",
    "            dates.append('--')\n",
    "    \n",
    "    # Time scrap    \n",
    "    date_time  = driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "    for j in date_time:\n",
    "        if (j.text is not None):\n",
    "            print (j.text)\n",
    "            times.append(j.text)\n",
    "        else:\n",
    "            times.append('--')\n",
    "    \n",
    "    df = pd.DataFrame({'Match': matches, 'Series': series, 'Place': places, 'Date': dates, 'Time': times})\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:30 IST\n",
      "05:00 IST\n",
      "05:00 IST\n",
      "05:30 IST\n",
      "09:30 IST\n",
      "09:30 IST\n",
      "14:00 IST\n",
      "09:30 IST\n",
      "18:00 IST\n",
      "18:00 IST\n",
      "18:00 IST\n",
      "18:00 IST\n",
      "18:00 IST\n",
      "14:30 IST\n",
      "14:30 IST\n",
      "09:30 IST\n",
      "15:30 IST\n",
      "15:30 IST\n",
      "15:30 IST\n",
      "15:30 IST\n",
      "                             Match    Series  \\\n",
      "0   TEST AUSTRALIA V INDIA 2020/21  1st Test   \n",
      "1   TEST AUSTRALIA V INDIA 2020/21  2nd Test   \n",
      "2   TEST AUSTRALIA V INDIA 2020/21  3rd Test   \n",
      "3   TEST AUSTRALIA V INDIA 2020/21  4th Test   \n",
      "4        TEST INDIA V ENGLAND 2021  1st Test   \n",
      "5        TEST INDIA V ENGLAND 2021  2nd Test   \n",
      "6        TEST INDIA V ENGLAND 2021  3rd Test   \n",
      "7        TEST INDIA V ENGLAND 2021  4th Test   \n",
      "8        T20I INDIA V ENGLAND 2021  1st T20I   \n",
      "9        T20I INDIA V ENGLAND 2021  2nd T20I   \n",
      "10       T20I INDIA V ENGLAND 2021  3rd T20I   \n",
      "11       T20I INDIA V ENGLAND 2021  4th T20I   \n",
      "12       T20I INDIA V ENGLAND 2021  5th T20I   \n",
      "13        ODI INDIA V ENGLAND 2021   1st ODI   \n",
      "14        ODI INDIA V ENGLAND 2021   2nd ODI   \n",
      "15        ODI INDIA V ENGLAND 2021   3rd ODI   \n",
      "16       TEST ENGLAND V INDIA 2021  1st Test   \n",
      "17       TEST ENGLAND V INDIA 2021  2nd Test   \n",
      "18       TEST ENGLAND V INDIA 2021  3rd Test   \n",
      "19       TEST ENGLAND V INDIA 2021  4th Test   \n",
      "\n",
      "                                            Place                   Date  \\\n",
      "0                         Adelaide Oval, Adelaide   Thursday 17 DECEMBER   \n",
      "1             Melbourne Cricket Ground, Melbourne   Saturday 26 DECEMBER   \n",
      "2                   Sydney Cricket Ground, Sydney    Thursday 07 JANUARY   \n",
      "3               Brisbane Cricket Ground, Brisbane      Friday 15 JANUARY   \n",
      "4              M. A. Chidambaram Stadium, Chennai     Friday 05 FEBRUARY   \n",
      "5              M. A. Chidambaram Stadium, Chennai   Saturday 13 FEBRUARY   \n",
      "6                 Sardar Patel Stadium, Ahmedabad  Wednesday 24 FEBRUARY   \n",
      "7                 Sardar Patel Stadium, Ahmedabad      Thursday 04 MARCH   \n",
      "8                 Sardar Patel Stadium, Ahmedabad        Friday 12 MARCH   \n",
      "9                 Sardar Patel Stadium, Ahmedabad        Sunday 14 MARCH   \n",
      "10                Sardar Patel Stadium, Ahmedabad       Tuesday 16 MARCH   \n",
      "11                Sardar Patel Stadium, Ahmedabad      Thursday 18 MARCH   \n",
      "12                Sardar Patel Stadium, Ahmedabad      Saturday 20 MARCH   \n",
      "13  Maharashtra Cricket Association Stadium, Pune       Tuesday 23 MARCH   \n",
      "14  Maharashtra Cricket Association Stadium, Pune        Friday 26 MARCH   \n",
      "15  Maharashtra Cricket Association Stadium, Pune        Sunday 28 MARCH   \n",
      "16                       Trent Bridge, Nottingham    Wednesday 04 AUGUST   \n",
      "17                                 Lord's, London     Thursday 12 AUGUST   \n",
      "18                              Headingley, Leeds    Wednesday 25 AUGUST   \n",
      "19                               The Oval, London  Thursday 02 SEPTEMBER   \n",
      "\n",
      "         Time  \n",
      "0   09:30 IST  \n",
      "1   05:00 IST  \n",
      "2   05:00 IST  \n",
      "3   05:30 IST  \n",
      "4   09:30 IST  \n",
      "5   09:30 IST  \n",
      "6   14:00 IST  \n",
      "7   09:30 IST  \n",
      "8   18:00 IST  \n",
      "9   18:00 IST  \n",
      "10  18:00 IST  \n",
      "11  18:00 IST  \n",
      "12  18:00 IST  \n",
      "13  14:30 IST  \n",
      "14  14:30 IST  \n",
      "15  09:30 IST  \n",
      "16  15:30 IST  \n",
      "17  15:30 IST  \n",
      "18  15:30 IST  \n",
      "19  15:30 IST  \n"
     ]
    }
   ],
   "source": [
    "item2('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item3(recieved_url):\n",
    "    \n",
    "    try:\n",
    "        driver.get(recieved_url)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised: ', e)\n",
    "    \n",
    "    # Inputing in searchbox for 'Selenium Exception Handling'\n",
    "    search_box = driver.find_element_by_id(\"gsc-i-id2\")\n",
    "    search_box.send_keys('selenium exception handling')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='gsc-search-button gsc-search-button-v2']\")\n",
    "    #WebDriverWait(driver, delay).until(EC.elementToBeClickable((search_btn)))\n",
    "    search_btn.submit()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    var_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Next window\n",
    "    except_page = driver.find_element_by_xpath(\"//div[@class='gs-webResult gs-result']/div/div/a\")\n",
    "    page_href = except_page.get_attribute('href')\n",
    "    \n",
    "    driver.get(page_href)\n",
    "    time.sleep(5)\n",
    "    var_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Exception data\n",
    "    except_data = driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr\")    \n",
    "    except_data = except_data[2:]\n",
    "    \n",
    "    for row in except_data:\n",
    "        except_name = row.find_elements_by_tag_name('td')[1].text\n",
    "        except_detail  \n",
    "        print (except_name)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='gs-webResult gs-result']/div/div/a\"}\n  (Session info: chrome=87.0.4280.88)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-724e123857c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitem3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.guru99.com/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-141-b95d6eaa7f96>\u001b[0m in \u001b[0;36mitem3\u001b[1;34m(recieved_url)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Next window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mexcept_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='gs-webResult gs-result']/div/div/a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mpage_href\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexcept_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='gs-webResult gs-result']/div/div/a\"}\n  (Session info: chrome=87.0.4280.88)\n"
     ]
    }
   ],
   "source": [
    "item3('https://www.guru99.com/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item4(recieved_url):\n",
    "    \n",
    "    try:\n",
    "        driver.get(recieved_url)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised: ', e)\n",
    "    \n",
    "    # india selection\n",
    "    select_page = driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[2]\")\n",
    "    select_href = select_page.get_attribute('href')\n",
    "    \n",
    "    try:\n",
    "        driver.get(select_href)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised: ', e)\n",
    "        \n",
    "    gdp_link = driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']/li[1]/a\")\n",
    "    gdp_href = gdp_link.get_attribute('href')\n",
    "\n",
    "    # hit the statewise gdp\n",
    "    try:\n",
    "        driver.get(gdp_href)\n",
    "        time.sleep(5)\n",
    "        var_soup = sp(driver.page_source, 'html.parser')\n",
    "    except TimeoutException as e:\n",
    "        print ('\\n Exception raised: ', e)\n",
    "        \n",
    "    table = driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr\")\n",
    "    \n",
    "    # Get the data    \n",
    "    ranks = []\n",
    "    states = []\n",
    "    gsdp18_19 = []\n",
    "    gsdp17_18 = []\n",
    "    share2017 = []\n",
    "    gdp_bln = []\n",
    "    \n",
    "    for row in table:\n",
    "        \n",
    "        # Rank\n",
    "        if (row.find_elements_by_tag_name('td')[0].text is not None):\n",
    "            ranks.append(row.find_elements_by_tag_name('td')[0].text)\n",
    "        else:\n",
    "            ranks.append('--')\n",
    "            \n",
    "        # State\n",
    "        if (row.find_elements_by_tag_name('td')[1].text is not None):\n",
    "            states.append(row.find_elements_by_tag_name('td')[1].text)\n",
    "        else:\n",
    "            states.append('--')\n",
    "            \n",
    "        # GSDP 18-19\n",
    "        if (row.find_elements_by_tag_name('td')[2].text is not None):\n",
    "            gsdp18_19.append(row.find_elements_by_tag_name('td')[2].text)\n",
    "        else:\n",
    "            gsdp18_19.append('--')\n",
    "            \n",
    "        # GSDP 17-18\n",
    "        if (row.find_elements_by_tag_name('td')[3].text is not None):\n",
    "            gsdp17_18.append(row.find_elements_by_tag_name('td')[3].text)\n",
    "        else:\n",
    "            gsdp17_18.append('--')\n",
    "            \n",
    "        # Share\n",
    "        if (row.find_elements_by_tag_name('td')[4].text is not None):\n",
    "            share2017.append(row.find_elements_by_tag_name('td')[4].text)\n",
    "        else:\n",
    "            share2017.append('--')\n",
    "            \n",
    "        # GDP ($Billion)\n",
    "        if (row.find_elements_by_tag_name('td')[5].text is not None):\n",
    "            gdp_bln.append(row.find_elements_by_tag_name('td')[5].text)\n",
    "        else:\n",
    "            gdp_bln.append('--')        \n",
    "        \n",
    "    df = pd.DataFrame({'Rank':ranks, 'State':states, 'GSDP18_19':gsdp18_19, 'GSDP17_18':gsdp17_18, 'Share2017':share2017, 'GDP($Billion)':gdp_bln})\n",
    "    print (df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State  GSDP18_19  GSDP17_18 Share2017  \\\n",
      "0     1                Maharashtra          -  2,411,600    14.11%   \n",
      "1     2                 Tamil Nadu  1,664,159  1,461,841     8.55%   \n",
      "2     3              Uttar Pradesh  1,542,432  1,376,324     8.05%   \n",
      "3     4                  Karnataka  1,535,224  1,350,257     7.90%   \n",
      "4     5                    Gujarat          -  1,314,680     7.69%   \n",
      "5     6                West Bengal  1,177,586    999,585     5.85%   \n",
      "6     7                  Rajasthan    929,124    835,558     4.89%   \n",
      "7     8             Andhra Pradesh    933,402    809,547     4.74%   \n",
      "8     9                  Telangana    865,688    753,811     4.41%   \n",
      "9    10             Madhya Pradesh    809,327    728,242     4.26%   \n",
      "10   11                     Kerala          -    700,532     4.10%   \n",
      "11   12                      Delhi    779,652    690,098     4.04%   \n",
      "12   13                    Haryana    707,126    626,054     3.66%   \n",
      "13   14                      Bihar    557,490    484,740     2.84%   \n",
      "14   15                     Punjab    521,861    479,141     2.80%   \n",
      "15   16                     Odisha    485,376    436,374     2.55%   \n",
      "16   17                      Assam          -    288,494     1.69%   \n",
      "17   18               Chhattisgarh    311,660    284,194     1.66%   \n",
      "18   19                  Jharkhand    307,581    276,243     1.62%   \n",
      "19   20                Uttarakhand    245,895    222,836     1.30%   \n",
      "20   21           Himachal Pradesh    153,181    140,613     0.82%   \n",
      "21   22            Jammu & Kashmir          -    138,488     0.81%   \n",
      "22   23                        Goa     77,172     70,493     0.41%   \n",
      "23   24                    Tripura          -     46,133     0.27%   \n",
      "24   25                 Chandigarh          -     38,806     0.23%   \n",
      "25   26                 Puducherry     36,656     32,962     0.19%   \n",
      "26   27                  Meghalaya          -     30,790     0.18%   \n",
      "27   28                   Nagaland          -     24,281     0.14%   \n",
      "28   29                    Manipur          -     23,968     0.14%   \n",
      "29   30                     Sikkim     26,786     23,495     0.14%   \n",
      "30   31          Arunachal Pradesh          -     22,045     0.13%   \n",
      "31   32                    Mizoram          -     19,457     0.11%   \n",
      "32   33  Andaman & Nicobar Islands          -      7,871     0.05%   \n",
      "\n",
      "   GDP($Billion)  \n",
      "0        374.196  \n",
      "1        226.827  \n",
      "2        213.558  \n",
      "3        209.513  \n",
      "4        203.993  \n",
      "5        155.101  \n",
      "6        129.650  \n",
      "7        125.614  \n",
      "8        116.965  \n",
      "9        112.998  \n",
      "10       108.698  \n",
      "11       107.079  \n",
      "12        97.142  \n",
      "13        75.215  \n",
      "14        74.346  \n",
      "15        67.710  \n",
      "16        44.764  \n",
      "17        44.097  \n",
      "18        42.863  \n",
      "19        34.576  \n",
      "20        21.818  \n",
      "21        21.489  \n",
      "22        10.938  \n",
      "23         7.158  \n",
      "24         6.021  \n",
      "25         5.115  \n",
      "26         4.778  \n",
      "27         3.768  \n",
      "28         3.719  \n",
      "29         3.646  \n",
      "30         3.421  \n",
      "31         3.019  \n",
      "32         1.221  \n"
     ]
    }
   ],
   "source": [
    "item4('http://statisticstimes.com/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
