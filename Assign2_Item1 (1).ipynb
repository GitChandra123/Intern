{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as sp\n",
    "import requests as rq\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'E:\\Chandralekha\\Study\\Intern_FlipRobo\\Webdriver_Selenium\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_site(site_url):\n",
    "    site_page = rq.get(site_url)\n",
    "    \n",
    "    # Parse the site content with html.parser\n",
    "    site_soup = sp(site_page.content, 'html.parser') \n",
    "    print (site_soup.prettify())\n",
    "    \n",
    "    return (site_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item1_scrap(m_url):\n",
    "    \n",
    "    driver.get(m_url)\n",
    "    time.sleep(5)\n",
    "    naukri_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    jobsrc = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    jobsrc.send_keys(\"Data Analyst\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    loc_search = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    loc_search.send_keys(\"Bangalore\")\n",
    "    time.sleep(2)\n",
    "               \n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    print (search_button.text)\n",
    "    search_button.click()\n",
    "    time.sleep(10)\n",
    "               \n",
    "    urls=[]\n",
    "    job_names=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    experience=[]\n",
    "    \n",
    "    jobs_soup = sp(driver.page_source, 'html.parser')\n",
    "    \n",
    "    jobtitles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    jobtitles = jobtitles[0:10]\n",
    "    for j in jobtitles:\n",
    "        job_names.append(j.text)        \n",
    "    \n",
    "    joblocations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")   \n",
    "    joblocations = joblocations[0:10]\n",
    "    for j in joblocations:\n",
    "        location.append(j.text)\n",
    "        \n",
    "    companies = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    companies = companies[0:10]\n",
    "    for j in companies:\n",
    "        company.append(j.text)\n",
    "    \n",
    "    experience_s = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    experience_s = experience_s[0:10]\n",
    "    for j in experience_s:\n",
    "        experience.append(j.text)\n",
    "        \n",
    "    df = pd.DataFrame({'jobtitle': job_names, 'location': location, 'company': company, 'experience': experience})\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search\n",
      "                                            jobtitle  \\\n",
      "0  Fresher Data Engineer / Data Scientist / Data ...   \n",
      "1  Immediate opening For Data Scientist/Data Analyst   \n",
      "2                              Business Data Analyst   \n",
      "3  SAS AML Data Analyst / Trainee & Data Science,...   \n",
      "4                               Hiring Data Analysts   \n",
      "5                               Hiring Data Analysts   \n",
      "6                                       Data Analyst   \n",
      "7                                 Study Data Analyst   \n",
      "8                                       Data Analyst   \n",
      "9                              Business Data Analyst   \n",
      "\n",
      "                              location  \\\n",
      "0      Delhi NCR, Bengaluru, Hyderabad   \n",
      "1  Chennai, Pune, Bengaluru, Hyderabad   \n",
      "2                            Bengaluru   \n",
      "3                Bengaluru(Whitefield)   \n",
      "4                            Bengaluru   \n",
      "5                            Bengaluru   \n",
      "6                     Bengaluru, India   \n",
      "7                            Bengaluru   \n",
      "8                            Bengaluru   \n",
      "9                            Bengaluru   \n",
      "\n",
      "                                             company experience  \n",
      "0                      ACHYUTAS SOFT PRIVATE LIMITED    0-2 Yrs  \n",
      "1  CAIA-Center For Artificial Intelligence & Adva...    0-3 Yrs  \n",
      "2                                             NetApp    2-3 Yrs  \n",
      "3                         MagicBase Royal BD Pvt Ltd    0-5 Yrs  \n",
      "4                  Flipkart Internet Private Limited    2-5 Yrs  \n",
      "5                  Flipkart Internet Private Limited    2-5 Yrs  \n",
      "6            GlaxoSmithKline Pharmaceuticals Limited    3-5 Yrs  \n",
      "7            GlaxoSmithKline Pharmaceuticals Limited    4-8 Yrs  \n",
      "8           Cognizant Technology Solutions India Ltd    3-4 Yrs  \n",
      "9                      GENPACT India Private Limited    3-6 Yrs  \n"
     ]
    }
   ],
   "source": [
    "item1_scrap('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
